{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Прогнозирование стоимости автомобиля по его характеристикам: \n",
    "# Часть 2: обучаем модели, сравниваем результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Над проектом работали: Бочкарева Ксения (bochkareva.2014@mail.ru), Журавлев Алексей (alexeizhuravlev@icloud.com)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor, StackingRegressor\n",
    "import warnings\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor, ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm.notebook import tqdm\n",
    "from catboost import CatBoostRegressor\n",
    "from datetime import timedelta, datetime, date\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from prettytable import PrettyTable\n",
    "from pandas import Series\n",
    "from sklearn.feature_selection import f_regression, mutual_info_regression\n",
    "import xgboost as xgb\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, когда данные готовы для ML, можно приступать к экспериментам. Начнем с базовой модели - линейной регрессии с дефолтными параметрами. Затем будем пробовать более сложные модели и посмотрим, какая покажет себя лучше всего. В конце поработаем над подбором гиперпараметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# полностью обработанные и готовые к работе данные\n",
    "data = pd.read_csv('final_data_module5.csv')\n",
    "data = data.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "sample_submission = pd.read_csv(\n",
    "    'sample_submission_module5.csv')  # шаблон сабмита на Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# введем функцию для подсчета ошибки MAPE\n",
    "\n",
    "def percentage_error(actual, predicted):\n",
    "    res = np.empty(actual.shape)\n",
    "    for j in range(actual.shape[0]):\n",
    "        if actual[j] != 0:\n",
    "            res[j] = (actual[j] - predicted[j]) / actual[j]\n",
    "        else:\n",
    "            res[j] = predicted[j] / np.mean(actual)\n",
    "    return res\n",
    "\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs(percentage_error(np.asarray(y_true), np.asarray(y_pred)))) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Базовая модель дефолтной линейной регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделим снова на train и test, т.к. все признаки уже обработаны\n",
    "train_data = data[data['sample'] == 1].drop(['sample'], axis=1)\n",
    "test_data = data[data['sample'] == 0].drop(['sample'], axis=1)\n",
    "\n",
    "# выделим целевую переменную и признаки\n",
    "X = train_data.drop(['Лог_Цена', 'Цена'], axis=1)\n",
    "y = train_data['Цена']\n",
    "\n",
    "# разделим на тренировочные и валидационные выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# прологарифмируем целевую переменную, тренировать модель будем на ней\n",
    "y_train_log = np.log(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.820687487587392"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# обучаем baseline модель\n",
    "baseline = LinearRegression().fit(X_train, y_train_log)\n",
    "\n",
    "# делаем \"логарифмированое\" предсказание\n",
    "y_pred_log = baseline.predict(X_test)\n",
    "\n",
    "# приводим цену к нужному формату: экспоненциируем и делаем кратность = 1000\n",
    "y_pred = (np.exp(y_pred_log)//1000)*1000\n",
    "\n",
    "# считаем ощибку\n",
    "# 16.8% ошибка, довольно неплохо для базовой модели\n",
    "mean_absolute_percentage_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пробуем сделать сабмит на платформу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пробуем Submission на Kaggle\n",
    "\n",
    "# берем тестовые данные (признаки)\n",
    "# данные для тестирование с Kaggle\n",
    "test_Kaggle = test_data.drop(['Лог_Цена', 'Цена'], axis=1)\n",
    "\n",
    "# предсказываем на них\n",
    "y_pred_test_l = baseline.predict(test_Kaggle)\n",
    "y_pred_test = (np.exp(y_pred_test_l)//1000)*1000\n",
    "\n",
    "# берем предсказанные цены\n",
    "sample_submission['price'] = y_pred_test\n",
    "\n",
    "# записываем в файл\n",
    "#sample_submission.to_csv('baseline_model.csv', index=False)\n",
    "\n",
    "# Ошибка 51.5% на Kaggle - плоховато"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ошибка на тестовых данных (на платформе Kaggle) базовой модели (линейной регрессии) составила 51.5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**По совету эксперта (и по мнению участников команды) нужно подобрать коэффициент, учитывающий изменения динамики ценообразования на рынке в среднем. Предположим, что к настоящему моменту цены в среднем выросли на 15%, то есть все предсказания мы будем умножать на 0.85.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9319543963456719"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_tree = RandomForestRegressor()\n",
    "reg_tree.fit(X_train, np.log(y_train))\n",
    "\n",
    "y_pred = (np.exp(reg_tree.predict(X_test))//1000)*1000\n",
    "\n",
    "# ошибка на тренировочной выборке 0.93%\n",
    "mean_absolute_percentage_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# делаем сабмит\n",
    "res_sub = (np.exp(reg_tree.predict(test_Kaggle))//1000)*1000\n",
    "sample_submission['price'] = ((res_sub*0.85)//1000)*1000\n",
    "\n",
    "#sample_submission.to_csv('reg_tree_15per.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission: также применим снижение предсказанной цены на 15%, после этого **МАРЕ на Каггле для RandomForestRegressor - 32.8%**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.824799247320334"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_xtree = ExtraTreesRegressor()\n",
    "reg_xtree.fit(X_train, np.log(y_train))\n",
    "\n",
    "y_pred = (np.exp(reg_xtree.predict(X_test))//1000)*1000\n",
    "\n",
    "# ошибка на тренировочной выборке 0.82%\n",
    "mean_absolute_percentage_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# делаем сабмит\n",
    "res_sub = (np.exp(reg_xtree.predict(test_Kaggle))//1000)*1000\n",
    "sample_submission['price'] = ((res_sub*0.85)//1000)*1000\n",
    "\n",
    "#sample_submission.to_csv('reg_xtree_15per.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission: также применим снижение предсказанной цены на 15%, после этого **МАРЕ на Каггле для ExtraTreesRegressor - 35.07%**. Самый слабый результат. Подбирать оптимальные параметры не будем, чтобы сэкономить время и вычислительную помщность наших ПК :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.827961761750432"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_gbr = GradientBoostingRegressor()\n",
    "reg_gbr.fit(X_train, np.log(y_train))\n",
    "\n",
    "y_pred = (np.exp(reg_gbr.predict(X_test))//1000)*1000\n",
    "\n",
    "# ошибка на тренировочной выборке 5.82%\n",
    "mean_absolute_percentage_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# делаем сабмит\n",
    "res_sub = (np.exp(reg_gbr.predict(test_Kaggle))//1000)*1000\n",
    "sample_submission['price'] = ((res_sub*0.85)//1000)*1000\n",
    "\n",
    "#sample_submission.to_csv('reg_gbr_15per.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission: также применим снижение предсказанной цены на 15%, после этого **МАРЕ на Каггле для GradientBoostingRegressor - 32.7%**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CatboostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1355335880832855"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_cat = CatBoostRegressor()\n",
    "reg_cat.fit(X_train, np.log(y_train), verbose=False)\n",
    "\n",
    "y_pred = (np.exp(reg_cat.predict(X_test))//1000)*1000\n",
    "\n",
    "# ошибка на тренировочной выборке 1.13%\n",
    "mean_absolute_percentage_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# делаем сабмит\n",
    "res_sub = (np.exp(reg_cat.predict(test_Kaggle))//1000)*1000\n",
    "sample_submission['price'] = ((res_sub*0.85)//1000)*1000\n",
    "\n",
    "#sample_submission.to_csv('reg_cat_15per.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission: также применим снижение предсказанной цены на 15%, после этого **МАРЕ на Каггле для CatBoost - 26.2%**. \n",
    "\n",
    "**Лучший результат среди моделей с дефолтными параметрами!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.174612308583004"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_xgb = xgb.XGBRegressor()\n",
    "reg_xgb.fit(X_train, np.log(y_train))\n",
    "\n",
    "y_pred = (np.exp(reg_xgb.predict(X_test))//1000)*1000\n",
    "\n",
    "# ошибка на тренировочной выборке 1.17%\n",
    "mean_absolute_percentage_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# делаем сабмит\n",
    "res_sub_xgb = (np.exp(reg_xgb.predict(test_Kaggle))//1000)*1000\n",
    "sample_submission['price'] = ((res_sub_xgb*0.85)//1000)*1000\n",
    "\n",
    "#sample_submission.to_csv('reg_xgb_15per.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission: также применим снижение предсказанной цены на 15%, после этого **МАРЕ на Каггле для XGBRegressor - 27.3%**. Второй алгоритм по качеству предсказания на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточные выводы:\n",
    "* Применение более сложных алгоритмов существенно улучшило метрику качества предсказания, особенно на тренировочной выброке.\n",
    "* Несмотря на то, что модели прекрасно справляются с задачей предсказания цен на тренировочной выборке, тестовый результат на платформе оказывается заметно хуже, что может быть вызвано большим временным интервалом между парсингом баз.\n",
    "* Для того, чтобы учесть изменившеюся динамику ценообразования, мы приняли решение домножать предсказанные цены на определенный коэффициент, то есть намеренно понижать предсказанные цены, что повысило точность модели на тестовых данных платформы. \n",
    "* Наконец, использование более сложных моделей даже с дефолтными параметрами позволило в лучшем случае снизить MAPE на тестовой выборке примерно в 2 раза по сравнению с базовой моделью линейной регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подбор гиперпараметров:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# random_grid = {'n_estimators': [int(x) for x in np.linspace(start = 100, stop = 400, num = 8)],\n",
    "# 'max_features': ['auto', 'sqrt', 'log2'],\n",
    "# 'max_depth': [int(x) for x in np.linspace(5, 15, num = 6)] + [None],\n",
    "# 'min_samples_split': [2, 5, 10],\n",
    "# 'min_samples_leaf': [1, 2, 4]}\n",
    "\n",
    "#gbr = GradientBoostingRegressor()\n",
    "# gbr_optimal = RandomizedSearchCV(estimator = gbr, param_distributions = random_grid, n_iter = 10, cv = 3,\\\n",
    "# verbose=10, random_state=42, n_jobs = -1)\n",
    "#gbr_optimal.fit(X_train, np.log(y_train))\n",
    "# gbr_optimal.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal parameters\n",
    "\n",
    "# {'n_estimators': 271,\n",
    "# 'min_samples_split': 10,\n",
    "# 'min_samples_leaf': 4,\n",
    "# 'max_features': 'log2',\n",
    "# 'max_depth': 11}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9850763292248863"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gbr = GradientBoostingRegressor(random_state=42, n_estimators=271,\n",
    "                                     min_samples_split=10, min_samples_leaf=4, max_features='log2', max_depth=11)\n",
    "\n",
    "best_gbr.fit(X_train, np.log(y_train))\n",
    "\n",
    "predict_gbr = (np.exp(best_gbr.predict(X_test))//1000)*1000\n",
    "mean_absolute_percentage_error(y_test, predict_gbr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подбор гиперпараметров заметно улучшил результат для GradientBoostingRegressor: было MAPE 5.82%, а стало 0.98%. Результат на Kaggle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# делаем сабмит\n",
    "res_sub = (np.exp(best_gbr.predict(test_Kaggle))//1000)*1000\n",
    "sample_submission['price'] = ((res_sub*0.85)//1000)*1000\n",
    "\n",
    "#sample_submission.to_csv('best_gbr_15per.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission: **МАРЕ на Каггле для GradientBoostingRegressor было 32.7%, а стало - 27.4%, что говорит о заметном улучшении.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#model = CatBoostRegressor(iterations=50, loss_function='MAPE', metric_period=10)\n",
    "\n",
    "# grid = {'learning_rate': [0.13, 0.14, 0.15]\n",
    "# ,'depth': [10,11,12]\n",
    "# ,'l2_leaf_reg': [7, 7.5, 8]\n",
    "# ,'random_strength': [0.2, 0.3, 0.4]}\n",
    "\n",
    "#grid_search_result = model.grid_search(grid,X=X_train,y=np.log(y_train),plot=False,verbose=False,cv=3)\n",
    "\n",
    "# grid_search_result['params']\n",
    "\n",
    "# optimal parameters\n",
    "#{'depth': 11, 'l2_leaf_reg': 8, 'random_strength': 0.3, 'learning_rate': 0.15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.589290554304865"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_optimal = CatBoostRegressor(iterations=100,\n",
    "                               random_seed=42,\n",
    "                               eval_metric='MAPE',\n",
    "                               custom_metric=['R2', 'MAE'],\n",
    "                               silent=True,\n",
    "                               learning_rate=0.15, depth=11,\n",
    "                               l2_leaf_reg=8, random_strength=0.3)\n",
    "\n",
    "cb_optimal.fit(X_train, np.log(y_train),\n",
    "               eval_set=(X_test, np.log(y_test)),\n",
    "               verbose=False,\n",
    "               use_best_model=True,\n",
    "               plot=False)\n",
    "\n",
    "predict_cb = (np.exp(cb_optimal.predict(X_test))//1000)*1000\n",
    "mean_absolute_percentage_error(y_test, predict_cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На тренировочной выборке метрика ухудшилась: была 1.13% с дефолтными параметрами, а стала 1.58%. Проверим на Кагле:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# делаем сабмит\n",
    "res_sub = (np.exp(cb_optimal.predict(test_Kaggle))//1000)*1000\n",
    "sample_submission['price'] = ((res_sub*0.85)//1000)*1000\n",
    "\n",
    "#sample_submission.to_csv('best_cb_15per.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На Кагле **метрика ухудшилась: стала 32.9%, а была 26.2% с дефолтными гиперпараметрами, что говорит об ухудшении результата.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "#max_features = ['auto', 'sqrt']\n",
    "#max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "# max_depth.append(None)\n",
    "#min_samples_split = [2, 5, 10]\n",
    "#min_samples_leaf = [1, 2, 4]\n",
    "#bootstrap = [True, False]\n",
    "# random_grid = {'n_estimators': n_estimators,\n",
    "# 'max_features': max_features,\n",
    "# 'max_depth': max_depth,\n",
    "# 'min_samples_split': min_samples_split,\n",
    "# 'min_samples_leaf': min_samples_leaf,\n",
    "# 'bootstrap': bootstrap}\n",
    "\n",
    "#rf = RandomForestRegressor(random_state=42)\n",
    "# rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid, n_iter=100,\n",
    "# cv=5, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# best parameters\n",
    "\n",
    "# {'n_estimators': 400,\n",
    "# 'min_samples_split': 2,\n",
    "# 'min_samples_leaf': 1,\n",
    "# 'max_features': 'sqrt',\n",
    "# 'max_depth': None,\n",
    "# 'bootstrap': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8872284820731196"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf = RandomForestRegressor(random_state=42, n_estimators=400, min_samples_split=2,\n",
    "                                min_samples_leaf=1, max_features='sqrt', max_depth=None, bootstrap=False)\n",
    "\n",
    "best_rf.fit(X_train, np.log(y_train))\n",
    "\n",
    "predict_rf = (np.exp(best_rf.predict(X_test))//1000)*1000\n",
    "mean_absolute_percentage_error(y_test, predict_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На тренировочной выборке метрика немного улучшилась: была 0.93% с дефолтными параметрами, а стала 0.88%. Проверим на Кагле:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# делаем сабмит\n",
    "res_sub = (np.exp(best_rf.predict(test_Kaggle))//1000)*1000\n",
    "sample_submission['price'] = ((res_sub*0.85)//1000)*1000\n",
    "\n",
    "#sample_submission.to_csv('best_rf_15per.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На Кагле **метрика немного улучшилась: стала 31.05%, а была 32.8% с дефолтными гиперпараметрами**, тем не менее RF по прежнему среди наиболее слабых моделей для данной задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8789908458512913"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# оптимальные параметры XGB заимствованы у других участников соревнования\n",
    "xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', colsample_bytree=0.5,\n",
    "                           learning_rate=0.05, max_depth=12, alpha=1, n_estimators=1000)\n",
    "xgb_reg.fit(X_train, np.log(y_train))\n",
    "\n",
    "y_pred = (np.exp(xgb_reg.predict(X_test))//1000)*1000\n",
    "\n",
    "mean_absolute_percentage_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На тренировочной выборке метрика немного улучшилась: была 1.17% с дефолтными параметрами, а стала 0.87%. Проверим на Кагле:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# делаем сабмит\n",
    "res_sub = (np.exp(xgb_reg.predict(test_Kaggle))//1000)*1000\n",
    "sample_submission['price'] = ((res_sub*0.85)//1000)*1000\n",
    "\n",
    "#sample_submission.to_csv('best_xgb_15per.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На Кагле **метрика немного улучшилась: стала 25.7%, а была 27.3% с дефолтными гиперпараметрами.** На данном этапе модель XGBRegressor c оптимальными гиперпараметрами показывает наилучший результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточные рузельтаты:\n",
    "* Не все модели улучшились после подбора оптимальных гиперпараметров.\n",
    "* Для XGBRegressor подбор гиперпараметров оказался наиболее продуктивным: модель показывает наилучший результат на платформе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging & Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работаем с нашими лучшими моделями на предыдущих шагах - **CatBoost (дефолтные параметры)** и **XGBRegressor (оптимальные параметры)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging для дефолтного CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1110003273783757"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "#reg_cat = CatBoostRegressor(verbose=False)\n",
    "#regr = BaggingRegressor(base_estimator=reg_cat,n_estimators=10, random_state=42).fit(X_train, np.log(y_train))\n",
    "\n",
    "#y_pred = (np.exp(regr.predict(X_test))//1000)*1000\n",
    "# mean_absolute_percentage_error(y_test, y_pred)   #1.11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика на базовом CatBoost была 1.13%, с бэггингом стала - 1.11%. На Кагле:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# делаем сабмит\n",
    "res_sub = (np.exp(regr.predict(test_Kaggle))//1000)*1000\n",
    "sample_submission['price'] = ((res_sub*0.85)//1000)*1000\n",
    "\n",
    "#sample_submission.to_csv('sub_cat_bag.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На Кагле **метрика немного улучшилась: стала 25.9%, а была на дефолтном CatBoost 26.2%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging для оптимального XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regr_bag_xgb = BaggingRegressor(base_estimator=xgb_reg,n_estimators=10, random_state=42).fit(X_train, np.log(y_train))\n",
    "#y_pred = (np.exp(regr_bag_xgb.predict(X_test))//1000)*1000\n",
    "\n",
    "# mean_absolute_percentage_error(y_test, y_pred) #0.88"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика на оптимальном XGBRegressor была 0.87%, с бэггингом стала - 0.88%. На Кагле:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# делаем сабмит\n",
    "res_sub = (np.exp(regr_bag_xgb.predict(test_Kaggle))//1000)*1000\n",
    "sample_submission['price'] = ((res_sub*0.85)//1000)*1000\n",
    "\n",
    "#sample_submission.to_csv('sub_xgb_bag.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На Кагле **метрика немного улучшилась: с бэггинг 24.8%, а была на просто оптимальном XGB 25.7%**. На данном этапе это наш лучший результат!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, мы решили вручную перебрать коэффициент, на который мы домножаем цены (уменьшаем цены) для нашей лучшей модели и проверить ошибку на платформе. Получили следующие результаты:\n",
    "\n",
    "* Без коррекции - МАРЕ 28.09%\n",
    "* Коррекция на 10% - МАРЕ 24.9%\n",
    "* **Коррекция на 13% - МАРЕ 24.76%** - наш лучший результат в целом.\n",
    "* Коррекция на 15% - МАРЕ 24.88%\n",
    "* Коррекция на 17% - МАРЕ 25.15%\n",
    "* Коррекция на 22% - МАРЕ 26.51%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вариант 1\n",
    "\n",
    "# estimators=[('regr', BaggingRegressor(base_estimator=CatBoostRegressor(),n_estimators=10, random_state=42)),\\\n",
    "# ('regr_bag_xgb', BaggingRegressor(base_estimator=xgb_reg,n_estimators=10, random_state=42))]\n",
    "\n",
    "#st_ensemble = StackingRegressor(estimators=estimators,final_estimator = CatBoostRegressor())\n",
    "\n",
    "#st_ensemble.fit(X_train, np.log(y_train))\n",
    "\n",
    "#y_pred = (np.exp(st_ensemble.predict(X_test))//1000)*1000\n",
    "\n",
    "# mean_absolute_percentage_error(y_test, y_pred)  #1.50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сабмит на платформу дал ошибку 25.21%, то есть просто бэггинг на XGB был лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вариант 2\n",
    "\n",
    "# estimators = [('regr', BaggingRegressor(base_estimator=CatBoostRegressor(), n_estimators=10, random_state=42)),\n",
    "# ('regr_bag_xgb', BaggingRegressor(base_estimator=xgb_reg, n_estimators=10, random_state=42))]\n",
    "\n",
    "# st_ensemble = StackingRegressor(estimators=estimators, final_estimator=GradientBoostingRegressor(\n",
    "# random_state=42, n_estimators=271, min_samples_split=10, min_samples_leaf=4, max_features='log2', max_depth=11))\n",
    "\n",
    "#st_ensemble.fit(X_train, np.log(y_train))\n",
    "\n",
    "#y_pred = (np.exp(st_ensemble.predict(X_test))//1000)*1000\n",
    "\n",
    "# mean_absolute_percentage_error(y_test, y_pred) #1.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "МАРЕ на платформе получилось 26.22% - то есть опять хуже чем XGB с бэггинге."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вариант 3\n",
    "\n",
    "# stimators = [('b_gbr', BaggingRegressor(GradientBoostingRegressor(random_state=42, n_estimators=800, min_samples_split=5,\n",
    "# min_samples_leaf=4, max_features='sqrt', max_depth=9),\n",
    "# n_estimators=3, n_jobs=1, random_state=42)),\n",
    "# ('xgb', xgb.XGBRegressor(objective='reg:squarederror', colsample_bytree=0.5,\n",
    "# learning_rate=0.05, max_depth=12, alpha=1, n_estimators=1000))]\n",
    "\n",
    "# st_ensemble_kag = StackingRegressor(estimators=estimators,\\\n",
    "# final_estimator=CatBoostRegressor(iterations=5000, random_seed=42, eval_metric='MAPE',custom_metric=[\n",
    "# 'R2', 'MAE'],silent=True, learning_rate=0.13, depth=12, l2_leaf_reg=8, random_strength=0.3))\n",
    "\n",
    "#st_ensemble_kag.fit(X_train, np.log(y_train))\n",
    "\n",
    "#y_pred = (np.exp(st_ensemble_kag.predict(X_test))//1000)*1000\n",
    "\n",
    "# mean_absolute_percentage_error(y_test, y_pred)  #1.51"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "МАРЕ на Каггле 27.33% - ещё хуже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Общие выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Тестовая база данных:**\n",
    "\n",
    "* База довольно \"грязная\", в ней много дублирующих друг друга признаков, но самое главное - нет понимания того КАК и самое главное КОГДА она была сделана. Цены на рынке подержанных машин в течение последнего года сильно изменялись и нам пришлось вводить корректирующий коэффициент (оптимальный - 13%) на предсказания, сделанные по актуальной базе. \n",
    "* Если бы мы знали когда была изготовлена база, то мы могли бы попытаться сделать корректирующие коэффициенты отдельно по каждой марке машин или по группам марок, что существенно улучшило бы показатели метрики. Кроме того понимание кода, который использовался при парсинге тестовой базы, помогло бы актуальную базу данных спарсить в виде более похожем на тестовую базу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Тренировочная база данных:**\n",
    "\n",
    "* Парсинг того объема данных, который использовался в работе, занял приблизительно 30 часов, что очень времязатратно и требует больших вычислительных мощностей и безперебойной работы интернета, что не всегда легко доступно.\n",
    "* У нас не хватило времени поработать с категорией \"комплектация\". Наличие некоторых опций в комплектации существенно влияет на цену и на ее изменение со временм (к примеру, кожаный салон будет дороже тканевого и наличие этой опции при прочих равных сделает машину более дорогой. Но времени пройтись по представительствам разных марок и спросить какие из около 300 представленных в базе опций будут в итоге существенно вляить на цену, а какие нет - нам не удалось."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Метрики и результаты:**\n",
    "\n",
    "* Мы провели многочисленные проверки работы моделей как с дефолтными настройками, так и с подобранными гиперпараметрами, использовали бэггинг и стеккинг. Последние два метода использовали не для всех моделей и их сочетаний в силу высокой ресурсоемкости процессов. \n",
    "* Наилучшие результаты показал CatboostRegressor на дефолтных настройках и XGBRegressor с применением бэггинга.\n",
    "* Серьезная разница между очень низкой метрикой МАРЕ на тренинговых данных и высокой на тестовых может объясняться несколькими причинами - переобучением модели на тренинге (но выявить это переобучение нам не удалось) и серьезным изменением рынка подержанных машин за прошедший год (динамика ценообразования).\n",
    "* Финальный результат метрики MAPE - 24.76% (на тестовых данных Kaggle) - и это наша лучшная модель: Бэггинг для оптимального XGBRegressor c 13%-ой поправкой цены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
