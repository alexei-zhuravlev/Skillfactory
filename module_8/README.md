# Car Price prediction


## Прогнозирование стоимости автомобиля по характеристикам
В этом ноутбуке реализованы следующие шаги:
1. Проведен EDA:
    - проведен анализ датасетов (количество пропусков, количество уникальных значений и т.п.)
    - проведен анализ признаков (присутствие дубликатов, распределение значений признаков и т.п.)
    - проведен корреляционный анализ (взаимная корреляция признаков, корреляция признаков с целевой переменной)
2. Добавлены новые признаки (такие как износ машины, возраст модели и т.п.)
3. Датасеты переработы по условиям, полученным из первых двух пунктов:
    - убраны дублирующие друг друга признаки
    - из некоторых категориальных признаков извлечены признаки числовые
    - проведена нормализация признаков
4. Обработан признак "описание модели" с целью  подготовить признак для работы NLP моделей
5. Проведена аугментация "картинок"
6. На полученном датасете обучены модели и сделаны предсказания:
    - наивная модель
    - CatBoost и LightAutoML для работы с табличными данными
    - Нейросеть для работы с табличными данными
    - NLP и multiple inputs модели
    - mulitple inputs модель, обрабатывающая одновременно табличные данные, текстовые данные и картинки
    - проведен блендинг
    - проведен "проброс признака"
7. Были использованы transfer-learning, fine tuning, управление learning rate

В __выводах__ - несколько слов о том, что получилось и чего не получилось сделать (и почему).

__Важный момент__ все предсказания дополнительно обрабатывались. Так как цены в датасете представлены кратными 10000 р, все предсказания (для вычисления MAPE и для сабмита на Kaggle) приводились к такому же виду.

### Что удалось сделать

1. Удалось сделать EDA и обнаружить влияние на цену марки машины, цвета, количества владельцев и т.п.
2. Удалось сравнить работу различных моделей (в том числе нейро-сети) для работы с табличными данными
3. Удалось провести обработку текста для работы NLP (убрав вводные слова, числительные, не кириллические символы и т.п., токенизировать текст)
4. Удалось сделать аугментацию картинок и отработать mutiple inputs модели
5. Удалось провести fine tuning финальной модели (по схеме - сначала обучаются все модели, кроме сверточной,
затем половина слоев сверточной модели, затем вся сверточная модель целиком), но это ухудшило разультат (11,83% МАРЕ вместо 11,54%)
6. Удалось провести блендинг (и он существенно улучшил результат)
7. Удалось сделать проброс признака (но он катастрофически ухудшил результат - до 13,8%)
8. Была попытка добавить полиномиальных признаков, но попытка ухудшила результат

### Что не удалось
1. Не удалось поэкспериментировать с fine-tuning (сделать другую последовательность в обучении и замораживании слоев и т.п.).
Не получилось это сделать просто в силу аппартаных ограничений. Просто не хватало времени на Kaggle, а на стороннем сервере,
где я всетаки смог реализовать одну из схем, просчет шел около 40 часов (!).
2. Не удалось поэкспериментировать с настройкой гипер-параметров моделей (опять же в силу аппаратных ограничений)
3. Не удалось попробовать обучение на фолдах (опять в силу аппаратных ограничений... с ужасом думаю сколько бы времени это заняло)
