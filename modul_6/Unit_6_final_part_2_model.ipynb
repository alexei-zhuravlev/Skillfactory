{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Проект 6. Рекомендательные системы.\n",
    "\n",
    "# Часть 2: обучение моделей, улучшение их, выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexeizh/Alexeizh_DST/venv/lib/python3.8/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "import scipy.sparse as sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from lightfm.evaluation import auc_score, precision_at_k, recall_at_k\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from lightfm import LightFM\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from IPython.core.display import display\n",
    "from tqdm import tqdm\n",
    "from datetime import date\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from prettytable import PrettyTable\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим подготовленные в другом ноутбуке данные. Это тренировочная база, в которую добавлены признаки, числовые признаки\n",
    "стандартизированы, категориальные переведены в dummies.\n",
    "\n",
    "Идея такова - сначала обучим \"базовую\" модель и получим на ней метрики. *В базовую модель сразу внесу изменения,\n",
    "полученные опытным путем в черновике - lerning rate = 0.08 (вместо 0.1) и NUM_COMPONENTS=35 (а не 30, как в оригинале)*\n",
    "\n",
    "Затем будем постепенно добавлять фичи и смотреть насколько это улучшает или ухудшает предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# загрузим тренировочную базу\n",
    "train = pd.read_csv(\n",
    "    '/Users/alexeizh/Alexeizh_DST/Unit_7/final_prjt/train_for_model.csv')\n",
    "train.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# разобьем на тестовую и тренинговую\n",
    "train_data, test_data = train_test_split(train, random_state=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# создаем разреженную матрицу\n",
    "total_users = max(train_data['userid'].max(), test_data['userid'].max()) + 1\n",
    "total_items = max(train_data['itemid'].max(), test_data['itemid'].max()) + 1\n",
    "ratings_coo = sparse.coo_matrix((train_data['rating'].astype(int),\n",
    "                                 (train_data['userid'],\n",
    "                                  train_data['itemid'])), shape=(total_users, total_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "NUM_THREADS = 4  # число потоков\n",
    "NUM_COMPONENTS = 35  # число параметров вектора\n",
    "NUM_EPOCHS = 20  # число эпох обучения\n",
    "\n",
    "model = LightFM(learning_rate=0.08, loss='logistic',\n",
    "                no_components=NUM_COMPONENTS)\n",
    "model_base = model.fit(ratings_coo, epochs=NUM_EPOCHS,\n",
    "                       num_threads=NUM_THREADS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "preds_base = model_base.predict(test_data.userid.values,\n",
    "                                test_data.itemid.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7478793066608688"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.roc_auc_score(test_data.rating, preds_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, ROC_AUC базовой модели составляет **0.7478793066608688**\n",
    "\n",
    "### Начнем добавлять (постепенно) фичи и смотреть как это повлияет на результат\n",
    "\n",
    "Для начала сделаем базу, из которой будем доставать фичи для обучения и тестов. _То есть сгруппируем всю имеющуюся базу\n",
    "по itemid и потом постепенно будем вынимать из нее фичи для дальнейшего обучения и тестов (сразу уберу из базы все признаки,\n",
    "касающиеся времени покупки - они бесползены, как показали опыты на \"черновиках\")_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "feat_data = train.groupby('itemid')[['verified', 'desc_subj',\n",
    "                                     'vote', 'numb_of_cat', 'rank_in_main', 'price', 'main_cat_All Beauty',\n",
    "                                     'main_cat_Amazon Home', 'main_cat_Arts, Crafts & Sewing',\n",
    "                                     'main_cat_Baby', 'main_cat_Camera & Photo',\n",
    "                                     'main_cat_Cell Phones & Accessories', 'main_cat_Grocery',\n",
    "                                     'main_cat_Grocery & Gourmet Food', 'main_cat_Health & Personal Care',\n",
    "                                     'main_cat_Home Audio & Theater', 'main_cat_Industrial & Scientific',\n",
    "                                     'main_cat_Musical Instruments', 'main_cat_Office Products',\n",
    "                                     'main_cat_Pet Supplies', 'main_cat_Software',\n",
    "                                     'main_cat_Sports & Outdoors', 'main_cat_Tools & Home Improvement',\n",
    "                                     'main_cat_Toys & Games']].mean().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# теперь сделаем реиндексацию, чтобы учесть все возможные itemid\n",
    "new_indexies = range(total_items)\n",
    "feat_data = feat_data.reindex(new_indexies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "verified                              18\n",
       "desc_subj                             18\n",
       "vote                                  18\n",
       "numb_of_cat                           18\n",
       "rank_in_main                          18\n",
       "price                                 18\n",
       "main_cat_All Beauty                   18\n",
       "main_cat_Amazon Home                  18\n",
       "main_cat_Arts, Crafts & Sewing        18\n",
       "main_cat_Baby                         18\n",
       "main_cat_Camera & Photo               18\n",
       "main_cat_Cell Phones & Accessories    18\n",
       "main_cat_Grocery                      18\n",
       "main_cat_Grocery & Gourmet Food       18\n",
       "main_cat_Health & Personal Care       18\n",
       "main_cat_Home Audio & Theater         18\n",
       "main_cat_Industrial & Scientific      18\n",
       "main_cat_Musical Instruments          18\n",
       "main_cat_Office Products              18\n",
       "main_cat_Pet Supplies                 18\n",
       "main_cat_Software                     18\n",
       "main_cat_Sports & Outdoors            18\n",
       "main_cat_Tools & Home Improvement     18\n",
       "main_cat_Toys & Games                 18\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посмотрим, не появились ли пропуски\n",
    "feat_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Заполним все пропуски нулями\n",
    "feat_data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Зададим так же матрицу идентичности\n",
    "identity_matrix = sparse.identity(total_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Теперь можем приступить к постепенному добавлению фичей и сравнению результатов.\n",
    "Пойдем от меньшего к большему - то есть сначала будем добавлять по одной фиче и смотреть, потом выберем\n",
    "самую хорошую и будем добавлять к ней дополнения.\n",
    "\n",
    "Начнем с **price**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# сначала зададим разреженную матрицу этого признака\n",
    "price_сsr = csr_matrix(feat_data[['price']].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# теперь соединим ее с матрицей идентичности, чтобы получить фичу для модели\n",
    "price_feat = sparse.hstack([identity_matrix, price_сsr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7475614642320709"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# теперь обучим модель, сделаем предсказание и посмотрим на изменение метрики\n",
    "model_price = model.fit(ratings_coo, epochs=NUM_EPOCHS,\n",
    "                        num_threads=NUM_THREADS, item_features=price_feat)\n",
    "\n",
    "preds_price = model_price.predict(test_data.userid.values,\n",
    "                                  test_data.itemid.values)\n",
    "\n",
    "sklearn.metrics.roc_auc_score(test_data.rating, preds_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Итак, ROC_AUC с фичей **price** составляет **0.7475614642320709**, что немного хуже чем базовая\n",
    "\n",
    "Посмотрим что будет, если использовать __rank_in_main__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# сначала зададим разреженную матрицу этого признака\n",
    "rank_сsr = csr_matrix(feat_data[['rank_in_main']].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# теперь соединим ее с матрицей идентичности, чтобы получить фичу для модели\n",
    "rank_feat = sparse.hstack([identity_matrix, rank_сsr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7474850350098888"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# теперь обучим модель, сделаем предсказание и посмотрим на изменение метрики\n",
    "model_rank = model.fit(ratings_coo, epochs=NUM_EPOCHS,\n",
    "                       num_threads=NUM_THREADS, item_features=rank_feat)\n",
    "\n",
    "preds_rank = model_rank.predict(test_data.userid.values,\n",
    "                                test_data.itemid.values)\n",
    "\n",
    "sklearn.metrics.roc_auc_score(test_data.rating, preds_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, ROC_AUC с фичей **rank_in_main** составляет **0.7474850350098888**, что немного хуже чем базовая\n",
    "и чем модель с ценой\n",
    "\n",
    "Посмотрим что будет, если использовать __desc_subj__ _(то есть объективность/субъективность описания товара)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# сначала зададим разреженную матрицу этого признака\n",
    "subj_сsr = csr_matrix(feat_data[['desc_subj']].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# теперь соединим ее с матрицей идентичности, чтобы получить фичу для модели\n",
    "subj_feat = sparse.hstack([identity_matrix, subj_сsr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# теперь обучим модель, сделаем предсказание и посмотрим на изменение метрики\n",
    "model_subj = model.fit(ratings_coo, epochs=NUM_EPOCHS,\n",
    "                       num_threads=NUM_THREADS, item_features=subj_feat)\n",
    "\n",
    "preds_subj = model_subj.predict(test_data.userid.values,\n",
    "                                test_data.itemid.values)\n",
    "\n",
    "sklearn.metrics.roc_auc_score(test_data.rating, preds_subj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, ROC_AUC с фичей **desc_subj** составляет **0.7326653244275896**, что заметно хуже чем базовая\n",
    "и чем предыдущие фичи\n",
    "\n",
    "Посмотрим что будет, если использовать __vote__ _(то есть количество проголосовавших за отзыв о товаре людей)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# сначала зададим разреженную матрицу этого признака\n",
    "vote_сsr = csr_matrix(feat_data[['vote']].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# теперь соединим ее с матрицей идентичности, чтобы получить фичу для модели\n",
    "vote_feat = sparse.hstack([identity_matrix,vote_сsr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# теперь обучим модель, сделаем предсказание и посмотрим на изменение метрики\n",
    "model_vote = model.fit(ratings_coo, epochs=NUM_EPOCHS,\n",
    "                       num_threads=NUM_THREADS, item_features=vote_feat)\n",
    "\n",
    "preds_vote = model_vote.predict(test_data.userid.values,\n",
    "                                test_data.itemid.values)\n",
    "\n",
    "sklearn.metrics.roc_auc_score(test_data.rating, preds_subj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, ROC_AUC с фичей **vote** составляет **0.7326653244275896**, что заметно хуже чем базовая\n",
    "и чем предыдущие фичи\n",
    "\n",
    "Посмотрим что будет, если использовать __numb_of_cat__ _(то есть количество категорий, в которых представлен товар)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# сначала зададим разреженную матрицу этого признака\n",
    "cat_num_сsr = csr_matrix(feat_data[['numb_of_cat']].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# теперь соединим ее с матрицей идентичности, чтобы получить фичу для модели\n",
    "cat_num_feat = sparse.hstack([identity_matrix, cat_num_сsr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7471678192483783"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# теперь обучим модель, сделаем предсказание и посмотрим на изменение метрики\n",
    "model_cat_num = model.fit(ratings_coo, epochs=NUM_EPOCHS,\n",
    "                          num_threads=NUM_THREADS, item_features=cat_num_feat)\n",
    "\n",
    "preds_cat_num = model_cat_num.predict(test_data.userid.values,\n",
    "                                      test_data.itemid.values)\n",
    "\n",
    "sklearn.metrics.roc_auc_score(test_data.rating, preds_cat_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, ROC_AUC с фичей **numb_of_cat** составляет **0.7471678192483783**, почти аналогично базовой модели\n",
    "\n",
    "Посмотрим что будет, если в качестве фичи использовать dummies категорий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# сначала зададим разреженную матрицу этого признака\n",
    "cat_сsr = csr_matrix(feat_data[['main_cat_All Beauty',\n",
    "                                'main_cat_Amazon Home', 'main_cat_Arts, Crafts & Sewing',\n",
    "                                'main_cat_Baby', 'main_cat_Camera & Photo',\n",
    "                                'main_cat_Cell Phones & Accessories', 'main_cat_Grocery',\n",
    "                                'main_cat_Grocery & Gourmet Food', 'main_cat_Health & Personal Care',\n",
    "                                'main_cat_Home Audio & Theater', 'main_cat_Industrial & Scientific',\n",
    "                                'main_cat_Musical Instruments', 'main_cat_Office Products',\n",
    "                                'main_cat_Pet Supplies', 'main_cat_Software',\n",
    "                                'main_cat_Sports & Outdoors', 'main_cat_Tools & Home Improvement',\n",
    "                                'main_cat_Toys & Games']].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# теперь соединим ее с матрицей идентичности, чтобы получить фичу для модели\n",
    "cat_feat = sparse.hstack([identity_matrix, cat_сsr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.691614962452294"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# теперь обучим модель, сделаем предсказание и посмотрим на изменение метрики\n",
    "model_cat = model.fit(ratings_coo, epochs=NUM_EPOCHS,\n",
    "                      num_threads=NUM_THREADS, item_features=cat_feat)\n",
    "\n",
    "preds_cat = model_cat.predict(test_data.userid.values,\n",
    "                              test_data.itemid.values)\n",
    "\n",
    "sklearn.metrics.roc_auc_score(test_data.rating, preds_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, ROC_AUC с фичей **dummies** составляет **0.691614962452294**, эта фича работает хуже всего.\n",
    "\n",
    "Посмотрим что будет, если в качестве фичи использовать сочетание трех более или менее удачных фичей:\n",
    "цена, рейтинг в основной категории и количество категорий, в которы представлен товар"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# сначала зададим разреженную матрицу этого признака\n",
    "best_сsr = csr_matrix(\n",
    "    feat_data[['price', 'rank_in_main', 'numb_of_cat']].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# теперь соединим ее с матрицей идентичности, чтобы получить фичу для модели\n",
    "best_feat = sparse.hstack([identity_matrix, best_сsr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7477287381309115"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# теперь обучим модель, сделаем предсказание и посмотрим на изменение метрики\n",
    "model_best = model.fit(ratings_coo, epochs=NUM_EPOCHS,\n",
    "                       num_threads=NUM_THREADS, item_features=best_feat)\n",
    "\n",
    "preds_best = model_cat.predict(test_data.userid.values,\n",
    "                               test_data.itemid.values)\n",
    "\n",
    "sklearn.metrics.roc_auc_score(test_data.rating, preds_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, ROC_AUC с тремя фичами составляет **0.7477287381309115**, все равно чуть хуже базовой модели.\n",
    "\n",
    "Попробуем сделать предсказния для тестовой базы kaggle на базовой и базовой с фичами модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# загружаем базу\n",
    "test = pd.read_csv('test_new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Признаки нужно нормализовать. Вернее нормализуем только **price, rank_in_main и numb_of_cat**,\n",
    "так как сейчас будем использовать только их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# отберем признаки для нормализации\n",
    "test_for_scaler = test[['price', 'rank_in_main', 'numb_of_cat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_for_scaler = scaler.fit_transform(test_for_scaler)\n",
    "\n",
    "test_scaled = pd.DataFrame(test_for_scaler, columns=[\n",
    "                           'price', 'rank_in_main', 'numb_of_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test['price'] = test_scaled['price']\n",
    "test['rank_in_main'] = test_scaled['rank_in_main']\n",
    "test['numb_of_cat'] = test_scaled['numb_of_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь обучаем модель и получаем предсказания для базовой версии и для версии с тремя фичами\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# создаем новую разреженную матрицу\n",
    "total_users = max(train['userid'].max(), test['userid'].max()) + 1\n",
    "total_items = max(train['itemid'].max(), test['itemid'].max()) + 1\n",
    "ratings_coo_sub = sparse.coo_matrix((train['rating'].astype(int),\n",
    "                                     (train['userid'],\n",
    "                                      train['itemid'])), shape=(total_users, total_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# используем модель с измененными настройками\n",
    "NUM_THREADS = 4  # число потоков\n",
    "NUM_COMPONENTS = 35  # число параметров вектора\n",
    "NUM_EPOCHS = 20  # число эпох обучения\n",
    "\n",
    "# обучаем базовую модель\n",
    "model = LightFM(learning_rate=0.08, loss='logistic',\n",
    "                no_components=NUM_COMPONENTS)\n",
    "model_base_tuned = model.fit(ratings_coo_sub, epochs=NUM_EPOCHS,\n",
    "                             num_threads=NUM_THREADS)\n",
    "\n",
    "# получаем предсказания на базовой модели\n",
    "preds_tuned = model_base_tuned.predict(test.userid.values,\n",
    "                                       test.itemid.values)\n",
    "\n",
    "# нормализуем предсказания\n",
    "normalized_preds_tuned = (preds_tuned - preds_tuned.min()) / \\\n",
    "    (preds_tuned - preds_tuned.min()).max()\n",
    "normalized_preds_tuned.min(), normalized_preds_tuned.max()\n",
    "\n",
    "# подгрузим шаблон для submission\n",
    "submission = pd.read_csv(\n",
    "    '/Users/alexeizh/Alexeizh_DST/Unit_7/final_prjt/final_hakaton/recommendationsv4/sample_submission.csv')\n",
    "\n",
    "# занесем предсказания базовой модели в шаблон\n",
    "submission['rating'] = normalized_preds_tuned\n",
    "\n",
    "# записываем в файл для публикации\n",
    "submission.to_csv('submission_base.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь сделаем обучение и предсказание на модели с тремя фичами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Для начала создадим базу из которой будем выбирать фичи.\n",
    "# Объединим train и test (но только столбцы для обучения\n",
    "data_feat_1 = train[['itemid', 'price', 'rank_in_main', 'numb_of_cat']].copy()\n",
    "data_feat_2 = test[['itemid', 'price', 'rank_in_main', 'numb_of_cat']].copy()\n",
    "data_feat_final = pd.concat([data_feat_1, data_feat_2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# теперь группируем по itemid для получения нужных фичей и последующего создания матрицы фичей\n",
    "feat_data_final = data_feat_final.groupby(\n",
    "    'itemid')[['price', 'rank_in_main', 'numb_of_cat']].mean().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# теперь сделаем реиндексацию, чтобы учесть все возможные itemid\n",
    "new_indexies_final = range(total_items)\n",
    "feat_data_final = feat_data_final.reindex(new_indexies_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price           0\n",
       "rank_in_main    0\n",
       "numb_of_cat     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посмотрим, не появились ли пропуски\n",
    "feat_data_final.isna().sum()\n",
    "# пропусков нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Зададим так же новую матрицу идентичности\n",
    "identity_matrix_final = sparse.identity(total_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# зададим новую разреженную матрицу признаков\n",
    "best_сsr_final = csr_matrix(\n",
    "    feat_data_final[['price', 'rank_in_main', 'numb_of_cat']].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# теперь соединим ее с матрицей идентичности, чтобы получить фичу для модели\n",
    "best_feat_final = sparse.hstack([identity_matrix_final, best_сsr_final])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# теперь обучим модель, сделаем предсказание и посмотрим на изменение метрики\n",
    "model_final = model.fit(ratings_coo_sub, epochs=NUM_EPOCHS,\n",
    "                        num_threads=NUM_THREADS, item_features=best_feat_final)\n",
    "\n",
    "preds_final = model_cat.predict(test.userid.values,\n",
    "                                test.itemid.values)\n",
    "\n",
    "# нормализуем предсказания\n",
    "normalized_preds_final = (preds_final - preds_final.min()) / \\\n",
    "    (preds_final - preds_final.min()).max()\n",
    "normalized_preds_final.min(), normalized_preds_final.max()\n",
    "\n",
    "# занесем предсказания базовой модели в шаблон\n",
    "submission['rating'] = normalized_preds_final\n",
    "\n",
    "# записываем в файл для публикации\n",
    "submission.to_csv('submission_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Время сделать сабмит на Каггл и посмотреть на результаты.\n",
    "Сабмит с базовой моделью - submission_base - 0.76806 (19 место)\n",
    "Сабмит с фичами - submission_final - 0.74705\n",
    "\n",
    "\n",
    "__Увы, но использование полученных фичей не улучшило результат работы модели,\n",
    "поэтому лучше остановиться на базовой модели с измененными настройками.__\n",
    "\n",
    "### Займемся эмбеддингами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "item_biases, item_embeddings = model_base_tuned.get_item_representations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import nmslib\n",
    "\n",
    "# Создаём наш граф для поиска\n",
    "nms_idx = nmslib.init(method='hnsw', space='cosinesimil')\n",
    "\n",
    "# Начинаем добавлять наши товары в граф\n",
    "nms_idx.addDataPointBatch(item_embeddings)\n",
    "nms_idx.createIndex(print_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Вспомогательная функция для поиска по графу\n",
    "def nearest_item_nms(itemid, index, n=10):\n",
    "    nn = index.knnQuery(item_embeddings[itemid], k=n)\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Попробуем найти товары, похожие на товар с неким itemid\n",
    "nbm = nearest_item_nms(37138, nms_idx)[0]\n",
    "nbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# запишем полученные эмбеддинги в файл для использования в другом ноутбуке\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('embeddings.pickle', 'wb') as f:\n",
    "    pickle.dump(item_embeddings, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Финальные выводы\n",
    "\n",
    "1. Активность покупателей в последнее время падает. Пик покупательской активности приходился на период 5-6 летней давности,\n",
    "с тех пор активность ощутимо уменьшается год от года.\n",
    "\n",
    "2. Покупательская активность примерно одинакова в течение года, с небольшим уменьшением в летне-осенний период\n",
    "\n",
    "3. Покупательсая активность в течение недели примерно одинакова, с небольшим падением активности в выходные дни\n",
    "\n",
    "4. Описание товара, его \"популярность\" у других пользователей не оказывает существенного влияния на решение о покупке\n",
    "(я считаю, что rating, показывающий \"нравится или не нравится\" покупателю товар связан с решением о покупке непосредственно)\n",
    "\n",
    "5. При холодном старте, тем не менее, новому покупателю я бы предлагал товар с наибольшим overall в категории\n",
    "(нужно \"спросить\" у покупателя товар какой категории он ищет). НО (!) этот показатель нужно модифицировать, учитывая голоса,\n",
    "отданные за тот же товар (overall + overall*vote), в случае одинаковых значений этого модифицированного показателя для разных\n",
    "товаров нужно предлагать тот, у кого выше эмоциональная оценка текста отзывов других пользователей.\n",
    "\n",
    "6. Внедрение нашей модели позволит увеличить количество покупок, если мы будем предлагать покупателю товар,\n",
    "который чаще всего покупают с уже купленным товаром (или в случае холодного старта - самые популярные товары\n",
    "в интересующей покупателя категории).\n",
    "\n",
    "7. В качестве метрики я бы испоьзовал полноту предсказаний. Так как предложить покупателю больше потенциально инетерсных\n",
    "товаров выгоднее, чем предложить один \"точно\" подходящий.\n",
    "\n",
    "8. Использование дополнительных фичей, которые можно было получить из имеющихся данных, только ухудшало работу модели,\n",
    "поэтому пришлось от них отказаться.\n",
    "\n",
    "9. К сожалению в предоставленных данных мало информации о собственно покупателе. Их использование могло бы (вероятно)\n",
    "улучшить результаты работы модели\n",
    "\n",
    "10. Был проведен анализ текстов отзывов покупателя, но использование этих данных (использовано в черновиках)\n",
    "не принесло никакого положительного результата\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
